{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tokens.txt has all the triplets, in which one line represante one example\n",
    "def cleanToken(t):\n",
    "    t = t.replace(\"...\", \"…\")\n",
    "    t = t.replace(\"tout.à.l'heure\", \"tout_à_l'heure\")\n",
    "    t = t.replace(\"</?font.*?>\", \"\")  # Remove the line using re.sub\n",
    "    t = t.replace(\"<sup>\", \"_\")\n",
    "    t = t.replace(\"</sup>\", \"_\")\n",
    "    t = t.replace(\"<u>\", \"\")\n",
    "    t = t.replace(\"</u>\", \"\")\n",
    "    t = t.replace(\"<sub>.*?</sub>\", \"\")\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignTokLemmgloss(text, lemgloss):\n",
    "    pattern = r'\\[\\[(\\w+)\\|\\|(\\w+)\\]\\]'\n",
    "    lemgloss = re.sub(pattern, r'[[\\1|\\2]]', lemgloss)\n",
    "\n",
    "\n",
    "    text_list = text.split(\"||\")\n",
    "    lemgloss_list = lemgloss.split(\"||\")\n",
    "    couple_list = []\n",
    "\n",
    "    if any(\"KLT\" in tok or \"Sujet\" in tok for tok in text_list) or any(\"KLT\" in lem or \"Sujet\" in lem for lem in lemgloss_list):\n",
    "        return couple_list\n",
    "\n",
    "    text_list_stripped = [tok.strip() for tok in text_list]\n",
    "    lemgloss_list_stripped = [lem.strip() for lem in lemgloss_list]\n",
    "\n",
    "    if \"standard\" in text.lower() or \"graphie\" in text.lower() or \"graphie\" in lemgloss.lower() :\n",
    "        text_list_stripped = [tok1 for tok1 in text_list_stripped if not (\"standard\" in tok1.lower() or \"graphie\" in tok1.lower() )]\n",
    "        text_list_stripped = [tok1 for tok1 in text_list_stripped if tok1]\n",
    "        lemgloss_list_stripped = [lem1 for lem1 in lemgloss_list_stripped if not (\"standard\" in lem1.lower() or \"graphie\" in lem1)]\n",
    "        lemgloss_list_stripped = [lem1 for lem1 in lemgloss_list_stripped if lem1]\n",
    "\n",
    "    else:\n",
    "        text_list_stripped = [tok1 for tok1 in text_list_stripped]\n",
    "        lemgloss_list_stripped = [lem1 for lem1 in lemgloss_list_stripped]\n",
    "\n",
    "\n",
    "    if text_list_stripped and text_list_stripped[-1] == \"\":\n",
    "        text_list_stripped.pop()\n",
    "    if lemgloss_list_stripped and lemgloss_list_stripped[-1] == \"\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if lemgloss_list_stripped and lemgloss_list_stripped[-1] == \"<elles>\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if lemgloss_list_stripped and lemgloss_list_stripped[-1] == \"_\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if lemgloss_list_stripped and re.search(r'\\d{4}', lemgloss_list_stripped[-1]):\n",
    "        return couple_list\n",
    "    if text_list_stripped and re.search(r'\\d{4}', text_list_stripped[-1]):\n",
    "        return couple_list\n",
    "    if text_list_stripped and \"colspan\" in text_list_stripped[-1]:\n",
    "        return couple_list\n",
    "    if text_list_stripped and \"[en place de\" in text_list_stripped[-1]:\n",
    "        text_list_stripped.pop()\n",
    "        text_list_stripped = [tok3 for tok3 in text_list_stripped if tok3]\n",
    "        lemgloss_list_stripped = [lem3 for lem3 in lemgloss_list_stripped if lem3]\n",
    "\n",
    "    if text == \"|| Ar yod || || oar || c'hweza. |||| ''Équivalent standardisé''\":\n",
    "        text_list_stripped = [\"Ar yod\", \"whitespace\", \"oar\", \"c'hweza.\"]\n",
    "    if lemgloss=='|| [[eo|était]] || [[komañs|commenc]].[[-et (Adj.)|é]] || [[art|le]] \"résistance\" || [[en em|se]] [[furmiñ|former]]':\n",
    "        lemgloss_list_stripped=['[[eo|était]]',\"[[komañs|commenc]].[[-et (Adj.)|é]]\",'[[art|le]]','\"résistance\"','[[en em|se]]','[[furmiñ|former]]']\n",
    "    if text==\"|| Roet || em boa || ma || rastell || din, || '''enep din'''.\":\n",
    "        text_list_stripped=['','Roet','em boa','ma','rastell','din,','enep','din']\n",
    "    if text==\"|| Me || a || gred || alato || e planto || Simone || patatez || er bloavezh-mañ.\":\n",
    "        text_list_stripped=['','Me','a','gred','alato','e planto','Simone','patatez','er','bloavezh-mañ.']\n",
    "    if lemgloss==\"|| [[posupl|même.si]] [[ma|que]]<sup>[[4]]</sup> || [[mont|allais]] [[da|à]] [[art|le]] [[nom propre|Australie]] || [[ne]]<sup>[[1]]</sup> || [[gwelout|verrais]] || [[ket|pas]] || [[kangourou|kangourou]].[[-ioù (PL.)|s]] || chaque.jour\":\n",
    "        lemgloss_list_stripped=['','[[posupl|même.si]] [[ma|que]]<sup>[[4]]</sup>','[[mont|allais]]','[[da|à]] [[art|le]]','[nom propre|Australie]]','[[ne]]<sup>[[1]]</sup>','[[gwelout|verrais]]','[[ket|pas]]','[[kangourou|kangourou]].[[-ioù (PL.)|s]]','chaque.jour']\n",
    "    if text_list_stripped and \"(=\" in text_list_stripped[-1]:\n",
    "        text_list_stripped.pop()\n",
    "    if text==\"|| un den || ha || 'laboura || mat || durant || an deiz || 'vez ket kavet '''bepred'''.\":\n",
    "        text_list_stripped=['','un den','ha',\"'laboura\",\"mat\",\"durant\",'an deiz','vez ket','kavet','bepred']\n",
    "    if lemgloss==\"|| [[bezañ préverbal|être]] / été || [[eo|suis]] || été || [[karout|aim]].[[-et (Adj.)|é]] || [[gant|avec]].[[pronom incorporé|lui]]\":\n",
    "        lemgloss_list_stripped=['','[[bezañ préverbal|être]]','/','été','[[eo|suis]]','été','[[karout|aim]].[[-et (Adj.)|é]]','[[gant|avec]].[[pronom incorporé|lui]]']\n",
    "    if \"rare occurrence de\" in text:\n",
    "        text_list_stripped = [ '','evid', 'an darn-vuia', 'deuz', 'an dud']\n",
    "    if lemgloss==\"|| [[mont|all]].[[-et (Adj.)|é]] [[pfi|lui]] || [[da|pour]]<sup>[[1]]</sup> || [[pourmen|promener]] || [[gant|avec]].[[pronom incorporé|elle]] || [[ne]]<sup>[[1]]</sup> [[ez eus|est]] || [[N'eus forzh pe X|qu'importe]] || [[ne]]<sup>[[1]]</sup> [[R]].3SGM [[kaout|a]] || [[ket|pas]] || envie\":\n",
    "        lemgloss_list_stripped=['','[[mont|all]].[[-et (Adj.)|é]] [[pfi|lui]]','[[da|pour]]<sup>[[1]]</sup>','[[pourmen|promener]]','[[gant|avec]].[[pronom incorporé|elle]]',\"[[N'eus forzh pe X|qu'importe]]\",'[[ne]]<sup>[[1]]</sup> [[R]].3SGM [[kaout|a]]','[[ket|pas]]','envie\"']\n",
    "    if lemgloss==\"|| [[ne]]<sup>[[1]]</sup> || [[ober|fait]] [[ket|pas]] [[met|sauf]] || quasi<sup>[[1]]</sup>.[[gwelout|voir]] || [[a|P]].[[pronom incorporé|lui]]\":\n",
    "        lemgloss_list_stripped=['','[[ne]]<sup>[[1]]</sup>','[[ober|fait]]','[[ket|pas]]','[[met|sauf]]','quasi<sup>[[1]]</sup>.[[gwelout|voir]]','[[a|P]].[[pronom incorporé|lui]]']\n",
    "    if text_list_stripped and \"Cornouaillais\" in text_list_stripped[-1]:\n",
    "        text_list_stripped.pop()\n",
    "        text_list_stripped = [tok5 for tok5 in text_list_stripped if tok5]\n",
    "        lemgloss_list_stripped = [lem5 for lem5 in lemgloss_list_stripped if lem5]\n",
    "    if text==\"|| Memes || (ma ne) || vefe || ket || '''bet''' || gwall || poazet. || ''Équivalent standardisé''\":\n",
    "        text_list_stripped=['Memes','ma','ne','vefe','ket','bet','gwall','poazet']\n",
    "    if \"Équivalent\" in text_list_stripped[-1]:\n",
    "        text_list_stripped.pop()\n",
    "        text_list_stripped = [tok4 for tok4 in text_list_stripped if tok4]\n",
    "        lemgloss_list_stripped = [lem4 for lem4 in lemgloss_list_stripped if lem4]\n",
    "    if text==\"||<font color=green>[</font color=green> || Evel || '''e''' || vamm <font color=green>]</font color=green> || a || gomz'''e''' || ''Équivalent standardisé''\":\n",
    "        text_list_stripped=['Evel','e','vamm <font color=green>]</font color=green>','a',\"gomz'''e'''\"]\n",
    "    if text==\"|| Me || || vefe || kontant || <u>gweled</u> || || '''anezañ''' || o || tond || amañ.\":\n",
    "        text_list_stripped=['','Me','','vefe','kontant','<u>gweled</u>','','anezañ','o','tond','amañ.']\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if text==\"|| '''Gwell''' || 'vize || dac'h || || bout || refuzet.\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if \"(glose corrigée)\" in text_list_stripped[-1]:\n",
    "        text_list_stripped.pop()\n",
    "        text_list_stripped = [tok6 for tok6 in text_list_stripped if tok6]\n",
    "        lemgloss_list_stripped = [lem6 for lem6 in lemgloss_list_stripped if lem6]\n",
    "    if text==\"|| ma || '''teu''' || dit || || koueza || klañv\" or text==\"|| '''Deuet''' || e oa || || dour || '''d''''ober\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if lemgloss_list_stripped[-1]==\"<font color=green>]</font color=green>\":\n",
    "        lemgloss_list_stripped.pop()\n",
    "    if text == \"|| 'Benn || || welan || da || betra || ema || '''deuet''' || 'nezhi, || me || || zo || trist.\":\n",
    "        text_list_stripped = ['Benn', 'whitespace', 'welan', 'da', 'betra', 'ema', 'deuet', 'nezhi', 'me', 'whitespace',\n",
    "                              'zo', 'trist']\n",
    "    if lemgloss==\"|| [[plad|plat]] || [[sant|Saint]] || [[nom propre|Éloi]] || [[P.e|à]] || [[poent|moment]] || [[ma|que]]<sup>[[4]]</sup> || [[vez|était]] || [[bouch|poulain]].[[-où (PL.)|s]] || [[bihan|petit]] || [[DEM|celui.ci]] || [[R]] || [[vez|était]] || [[traoù|choses]] || dedans || _\":\n",
    "        lemgloss_list = lemgloss.split(\"||\")\n",
    "        lemgloss_list_stripped = [lem.strip() for lem in lemgloss_list]\n",
    "    if \"(cf.\" in text:\n",
    "        text_list_stripped=['ser', 'geipal', 'Doue']\n",
    "        lemgloss_list_stripped=['','courir','[[Doue|Dieu]]']\n",
    "    if \"[[*]]\" in text_list_stripped[0]:\n",
    "        text_list_stripped=text_list_stripped[1:]\n",
    "        lemgloss_list_stripped=lemgloss_list_stripped[:-2]\n",
    "    if text==\" [[*]] || Den || ebet || zo || deuet || (> N'eus deuet den ebet)\":\n",
    "        text_list_stripped=['Den','ebet','zo','deuet']\n",
    "        lemgloss_list_stripped=['[[den|personne]]','aucun','[[zo|est]]', '[[dont|ven]].[[-et (Adj.)|u]]']\n",
    "    if text==\"|| Ma || '''moc'h''' || bien, || mé || zo || 'weu !\":\n",
    "        lemgloss_list_stripped=['','[[ma(r)|si]]<sup>[[4]]</sup>',\"[[COP|êtes]]\",'[[bihan|petit]]','[[pfi|moi]]','[[zo|est]]',\"[[ivez|aussi]]\"]\n",
    "    if text==\"|| || Tristaet-tout || e oa || Matriona || baour || o || tont || d'ar || gêr.\":\n",
    "        lemgloss_list_stripped=lemgloss_list_stripped[:-1]\n",
    "    if text==\"|| N' '''eus''' || <u>netra vat</u> || en || ti-mañ. || ([[*]] Netra n'eo mat)\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| '''Kracherc'h''' || zo || || nhijal || diboa || mintin-m'.\":\n",
    "        text_list_stripped=['',\"'''Kracherc'h'''\",'zo','whitespace','nhijal','diboa',\"mintin-m'.\"]\n",
    "        lemgloss_list_stripped=['','[[krak-|pfx]].neige','[[zo|est]]', '[[particule o|à]]<sup>[[4]]</sup>', '[[nijal|voler]]', '[[abaoe|depuis]]','[[mintin|matin]]-[[DEM|ci]]']\n",
    "    if text==\"|| Ne || oa || ket || ur rahouenn || etre || '''eñ''' || hag || an daol. || ([[*]] etrezañ hag an daol)\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| ober || al liamm || etre || '''int''' || hag || ar re || yaouankoc'h |||| ([[*]] etrezo hag...)\":\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "    if text==\"|| Me || am-eus || c'hoant || da || lavared || penaoz || ema || ar wirionez || gant || ar skolaer ! |||| ''Breton trégorrois''\":\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "    if text==\"|| an neb || a || venn || || a || '''c'hell'''.\":\n",
    "        text_list_stripped=['an neb','a','venn','whitespace',\"'''c'hell'''.\"]\n",
    "        lemgloss_list_stripped=['[[art|le]] [[Nep X|nep]]','[[R]]<sup>[[1]]</sup>','[[mennout|veut]]','<font color=green>[</font color=green><sub>[[VP]]</sub> ø <font color=green>]</font color=green> <sup>[[1]]</sup>','peut']\n",
    "    if text==\"|| Graet || ' || vez || alies || gant || kig-yar, || met || '''gall''' || ' || '''vez''' || bout || graet || ivez || gant || pesk. || (''gallet'')\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| Soñjal || a || raen || a-zevri ||| en desped || din, || <u>en istor</u> || a || '''c'halljen''' || '''da''' || ober.\":\n",
    "        lemgloss_list_stripped=lemgloss_list_stripped[:-1]\n",
    "    if text==\"|| Clasquit || || <u>ur c'honfessour</u> || an dina || || a || '''ellot''' || '''da''' || gaout.\":\n",
    "        lemgloss_list_stripped=lemgloss_list_stripped[:-1]\n",
    "    if text==\"|| N' || eus || nemet || '''mont''' || '''gant''' || red || an istor || d'ober || _\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| Ne || '''huilé''' || din || ebet. || ''Vannetais''\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| Pad || an dibenn || zunn || emefe || oto || Jean-Paul. || (HAB)\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| Be || { '''zo / meus''' } || ma || loeroù || a gouezh. |||| (préférence pour ''meus'')\":\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "    if text==\"|| ken || ma || çet || ma || bragoù !\":\n",
    "        lemgloss_list_stripped=['','tant','[[ema|est]]', '[[ket|pas]]','[[POSS|mon]]', 'pantalons']\n",
    "    if text==\"|| Benn || diriaou || ' || tigoueho || ma || sraoù. || ([[*]] … meus ma sraoù o tont.)\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| Ne || galfec'h || ket || chom || aze || memes || (la) ma || vefec'h || kourachus. || ([-mut] revendiqué sur ''ne galfec'h'')\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| || emañ ket || memes || hini || ganin. |||| ''Graphie standard''\":\n",
    "        text_list_stripped=['whitespace',\"emañ ket\",'memes','hini','ganin']\n",
    "    if text==\"|| 'Oan || o || vond || da brena || an || _ || all\":\n",
    "        text_list_stripped=['','Oan','o','vond','da','brena','an','_','all']\n",
    "    if text==\"|| Me am-eus || c'hoant || da lavared || penaoz || ema ar wirionez || gant ar skolaer ! || ''Treger Breton''\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| abaoe || ez || eo || savet || emañ en || imor || fall || ''Graphie standard''\":\n",
    "        text_list_stripped=['abaoe','ez','eo','savet','emañ','en','imor','fall']\n",
    "    if text==\"|| Be || '''meus''' || '''ma''' || loeroù || a || gouezh. |||| (préféré)\":\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "    if text==\" || Ma || chosetoù || '''a''' || '''zo''' || glip. |||||| (première proposition)\":\n",
    "        text_list_stripped=text_list_stripped[:-3]\n",
    "    if text==\" || Me || '''meus''' || '''ma''' || chosetoù || glip. |||| (également accepté)\":\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "    if text==\"|| ( <u>Ar sorserez</u> || / <u>an avel</u>)|| '''neus''' | |kaset || Dorothée || da Vro Oz.\":\n",
    "        text_list_stripped=['','<u>Ar sorserez</u>','/ <u>an avel</u>',\"'''neus'''\",'kaset','Dorothée','da Vro Oz.']\n",
    "    if lemgloss==\"|| [[pfi|elle]] || [[R]] || [[lavarout|d]].[[-et (Adj.)|it]] || [[COP|serait]] || [[bet|été]] || [[particule o|à]]<sup>[[1]]</sup> || envier || [[dimeziñ|marier]]\":\n",
    "        lemgloss_list_stripped=['','[[pfi|elle]]','[[R]]','[[lavarout|d]].[[-et (Adj.)|it]]','[[COP|serait]]','[[bet|été]] [[particule o|à]]<sup>[[1]]</sup>','envier','[[dimeziñ|marier]]']\n",
    "    if text==\"|| Amañ, || war gern || Menez-Hom || e vez eur || gouél || braz, || bep || ploaz, || '''neketa''' !\":\n",
    "        text_list_stripped=['','Amañ,','war','gern','Menez-Hom','e vez eur','gouél','braz,','bep','ploaz',\"'''neketa''' !\"]\n",
    "    if text==\"|| my a grys || '''bos''' Tom || ow palas || y'n lowarth. || ''Cornique''\":\n",
    "        text_list_stripped=text_list_stripped[:-1]\n",
    "    if text==\"|| '''Kontant''' || on || da || sikour || betek || || vin || paeet. || ''Graphie standard''\":\n",
    "        text_list_stripped=[\"'''Kontant'''\",'on','da','sikour','betek','whitespace','vin','paeet.']\n",
    "    if \"(Pas de coréférence possible)\" in text_list_stripped[-1]:\n",
    "        text_list_stripped=text_list_stripped[:-2]\n",
    "\n",
    "\n",
    "\n",
    "    #print(len(lemgloss_list_stripped),len(text_list_stripped))\n",
    "    if len(text_list_stripped) == len(lemgloss_list_stripped):\n",
    "        for tok, lemmgloss in zip(text_list_stripped, lemgloss_list_stripped):\n",
    "            tok = cleanToken(tok)\n",
    "            lemmgloss = cleanToken(lemmgloss)\n",
    "            if tok and lemmgloss:\n",
    "                couple_list.append((tok, lemmgloss))\n",
    "    else:\n",
    "        punctuation_marks = ['!', '.', ',', '?', ';', ':']\n",
    "        for punctuation in punctuation_marks:\n",
    "            if text_list_stripped and text_list_stripped[-1].endswith(punctuation) and not lemgloss_list_stripped[-1].endswith(punctuation):\n",
    "                lemgloss_list_stripped.append(punctuation)\n",
    "\n",
    "        if len(text_list_stripped) == len(lemgloss_list_stripped):\n",
    "            for tok, lemmgloss in zip(text_list_stripped, lemgloss_list_stripped):\n",
    "                tok = cleanToken(tok)\n",
    "                lemmgloss = cleanToken(lemmgloss)\n",
    "                if tok and lemmgloss:\n",
    "                    couple_list.append((tok, lemmgloss))\n",
    "        else:\n",
    "            for punctuation in punctuation_marks:\n",
    "                if lemgloss_list_stripped and lemgloss_list_stripped[-1].endswith(punctuation) and not \\\n",
    "                text_list_stripped[-1].endswith(punctuation):\n",
    "                    text_list_stripped.append(punctuation)\n",
    "\n",
    "            if len(text_list_stripped) == len(lemgloss_list_stripped):\n",
    "                for tok, lemmgloss in zip(text_list_stripped, lemgloss_list_stripped):\n",
    "                    tok = cleanToken(tok)\n",
    "                    lemmgloss = cleanToken(lemmgloss)\n",
    "                    if tok and lemmgloss:\n",
    "                        couple_list.append((tok, lemmgloss))\n",
    "            else:\n",
    "                with open(\"not_couple.txt\", \"a\") as file:\n",
    "                    file.write(\"text\\n\")\n",
    "                    file.write(f\"{text}\\n\")\n",
    "                    file.write(\"lemgloss\\n\")\n",
    "                    file.write(f\"{lemgloss}\\n\")\n",
    "                    file.write(\"__________________\\n\")\n",
    "    return couple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couple2tokobjects(couple):\n",
    "    text, lemmgloss = couple\n",
    "\n",
    "    text_list = text.split(\"||\")\n",
    "    lemmgloss_list = lemmgloss.split(\"||\")\n",
    "\n",
    "    tok_objects = []\n",
    "\n",
    "    for i in range(len(text_list)):\n",
    "        tok = text_list[i].strip()\n",
    "        lemmgloss_item = lemmgloss_list[i].strip()\n",
    "\n",
    "        if '[[' in lemmgloss_item:\n",
    "            try:\n",
    "                lemma_parts = []\n",
    "                gloss_parts = []\n",
    "\n",
    "                while '[[' in lemmgloss_item:\n",
    "                    start_index = lemmgloss_item.index('[[')\n",
    "                    end_index = lemmgloss_item.index(']]')\n",
    "\n",
    "                    part = lemmgloss_item[start_index+2:end_index].strip()\n",
    "\n",
    "                    if '|' in part:\n",
    "                        lemma_part, gloss_part = part.split('|')\n",
    "                        lemma_parts.append(lemma_part.strip())\n",
    "                        gloss_parts.append(gloss_part.strip())\n",
    "                    else:\n",
    "                        tok_object = {}\n",
    "                        tok_object['note'] = part\n",
    "                        tok_objects.append(tok_object)\n",
    "\n",
    "                    lemmgloss_item = lemmgloss_item[end_index+2:]\n",
    "\n",
    "                for j in range(len(lemma_parts)):\n",
    "                    tok_object = {}\n",
    "                    tok_object['tok'] = lemma_parts[j].split('|')[0].strip()\n",
    "                    tok_object['lemma'] = lemma_parts[j].split('|')[0].strip()\n",
    "                    tok_object['gloss'] = gloss_parts[j].split('|')[0].strip()\n",
    "\n",
    "                    # Modify the gloss to 'petit' if both tok and lemma contain '-ig'\n",
    "                    if '-ig' in tok_object['tok'] and '-ig' in tok_object['lemma']:\n",
    "                        tok_object['gloss'] = 'petit'\n",
    "\n",
    "                    tok_objects.append(tok_object)\n",
    "\n",
    "            except ValueError:\n",
    "                pass\n",
    "        else:\n",
    "            tok_object = {}\n",
    "            tok_object['tok'] = tok\n",
    "            tok_object['lemma'] = tok\n",
    "            tok_object['gloss'] = lemmgloss_item\n",
    "\n",
    "            tok_objects.append(tok_object)\n",
    "\n",
    "    return tok_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_lines():\n",
    "    filename = \"all_line_objects.txt\"\n",
    "    all_examples = []\n",
    "\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    example = {}\n",
    "    store_text = False\n",
    "    store_lemgloss = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if store_text:\n",
    "            if line.startswith(\"||\"):\n",
    "                example[\"text\"] = line[0:]\n",
    "            else:\n",
    "                example[\"text\"] = line[3:]\n",
    "            store_text = False\n",
    "        elif store_lemgloss:\n",
    "            example[\"lemgloss\"] = line\n",
    "            store_lemgloss = False\n",
    "\n",
    "            if example[\"text\"] != \"\" and example[\"lemgloss\"] != \"None\":\n",
    "                all_examples.append(example)\n",
    "\n",
    "            example = {}\n",
    "        elif line == \"text\":\n",
    "            store_text = True\n",
    "        elif line == \"lemgloss\":\n",
    "            store_lemgloss = True\n",
    "\n",
    "    # Process each example\n",
    "    for example in all_examples:\n",
    "        text = example[\"text\"]\n",
    "        lemgloss = example[\"lemgloss\"]\n",
    "\n",
    "        example_info = alignTokLemmgloss(text, lemgloss)\n",
    "        tok_objects_list = []\n",
    "        #if example_info!=\"[]\":\n",
    "            #print(example_info)\n",
    "\n",
    "\n",
    "        for couple in example_info:\n",
    "            tok_objects = couple2tokobjects(couple)\n",
    "            tok_objects_list.extend(tok_objects)\n",
    "\n",
    "        if tok_objects_list:\n",
    "            print(tok_objects_list)\n",
    "\n",
    "\n",
    "whole_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
